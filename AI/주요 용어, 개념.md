
# 데이터 구조

## 스칼라 (Scalar)

---

> 크기만을 가지는 물리량, 단일 실숫값.

**예시**: 무게, 온도, 길이

벡터 공간을 이루는 Field의 원소를 의미한다. 좌표계가 바뀌어도 값이 변하지 않으므로 불변량(invariant)으로 간주한다. 스칼라끼리는 일반적인 덧셈, 곱셈을 따름.

```python
# 스칼라 예시
temperature = 25.5      # 온도
mass = 10.2            # 질량
speed = 60.0           # 속력
```

### AI에서의 사용

- **손실 함수 값**: 모델이 얼마나 틀렸는지 나타내는 하나의 숫자
- **학습률**: 모델이 얼마나 빠르게 학습할지 정하는 값
- **정확도**: 모델의 성능을 나타내는 백분율 (예: 95.2%)
- **임계값**: 분류를 위한 기준점 (예: 0.5)

---

## 벡터 (Vector)

---

벡터는 n개의 스칼라로 이루어진 순서쌍, 벡터 공간의 원소. 방향과 크기로 설명하는 물리적 벡터와 좌표 자유도를 강조하는 추상 벡터가 구별됨.

> **수학/물리학** - 크기와 방향을 가지는 물리량, 좌표값  
> **컴퓨터** - 1차원 배열  
> **ML** - 여러 개의 특성으로 표현된 데이터

벡터는 선형 조합으로 표현 가능해 분석·기하학의 연결 고리가 된다.

```python
# 벡터 예시
velocity = [10, 5, -2]        # 3차원 속도 벡터
word_embed = [0.2, -0.1, 0.5, 0.8, -0.3]  # 5차원 단어 임베딩
feature_vector = [25, 50000, 3, 1]         # [나이, 연봉, 자녀수, 결혼여부]
```

### 기본 연산

- **덧셈**: `u + v` (성분별 덧셈)
- **스칼라 곱**: `k × v` (모든 성분에 k 곱하기)
- **내적**: `u · v` (유사도, 투영 계산)
- **크기**: `||v||` (벡터의 길이)

### 활용 분야

- **물리**: 속도, 힘, 전기장
- **ML**: 단어 임베딩 300-D, 이미지 784-D 픽셀, 특성 벡터
- **추천 시스템**: 사용자/아이템 프로필 벡터
- **컴퓨터 비전**: 특징점 좌표

---

## 행렬 (Matrix)

---

행렬은 m×n 스칼라 격자(2차원 배열)이며, **선형 변환(linear transformation)**을 좌표로 표현한 것과 동치다.

> **수학** - 선형 변환을 나타내는 구조  
> **컴퓨터** - 2차원 배열  
> **ML** - 데이터 집합, 가중치, 관계 표현

```python
# 행렬 예시
rotation_matrix = [
    [0.866, -0.5],     # 30도 회전 행렬
    [0.5,   0.866]
]

weight_matrix = [
    [0.2, -0.1, 0.3],  # 뉴런1 → 3개 출력
    [0.5,  0.2, -0.1], # 뉴런2 → 3개 출력
    [-0.1, 0.4,  0.2]  # 뉴런3 → 3개 출력
]

image_grayscale = [
    [255, 128, 64],    # 첫 번째 행 픽셀
    [200, 150, 100],   # 두 번째 행 픽셀
    [180, 90,  45]     # 세 번째 행 픽셀
]
```

### 주요 연산

- **행렬-벡터 곱**: `A × v` → 벡터를 다른 벡터로 변환
- **행렬-행렬 곱**: `A × B` → 변환의 합성
- **전치**: `A^T` → 행과 열 바꾸기
- **역행렬**: `A^(-1)` → 역변환 (존재할 때)

### AI에서의 사용

- **신경망 가중치**: 레이어 간 연결 강도
- **흑백 이미지**: 픽셀 밝기 값의 2D 배열
- **attention 가중치**: 단어 간 관계 매트릭스
- **데이터셋**: 행(샘플) × 열(특성) 형태
- **공분산 행렬**: 특성 간 상관관계
- **혼동 행렬**: 분류 성능 평가

---

## 텐서 (Tensor)

---

텐서는 **다차원 배열**의 일반화된 형태로, 스칼라(0차), 벡터(1차), 행렬(2차)을 포함하는 상위 개념이다.

> **수학** - 다중선형 변환을 나타내는 구조  
> **물리학** - 좌표 변환에 따라 특정 규칙으로 변하는 양  
> **컴퓨터** - N차원 배열  
> **딥러닝** - 모든 데이터의 통합 표현

```python
# 3차원 텐서: 컬러 이미지 (높이 × 폭 × 채널)
color_image = [
    [[255, 0, 0], [0, 255, 0]],    # 첫 번째 행: 빨강, 초록
    [[0, 0, 255], [255, 255, 0]]   # 두 번째 행: 파랑, 노랑
]
# shape: (2, 2, 3) = 높이 2, 폭 2, RGB 3채널

# 4차원 텐서: 이미지 배치 (배치 × 채널 × 높이 × 폭)
batch_images = torch.randn(32, 3, 224, 224)  # 32장의 224×224 RGB 이미지
```

### 차원별 활용

|차원|이름|모양 예시|AI 활용 사례|
|---|---|---|---|
|**0차원**|스칼라|`5.2`|손실값, 학습률|
|**1차원**|벡터|`[1,2,3,4]`|단어 임베딩, 특성|
|**2차원**|행렬|`[[1,2],[3,4]]`|가중치, 흑백 이미지|
|**3차원**|3D 텐서|`(H,W,C)`|컬러 이미지, 시계열|
|**4차원**|4D 텐서|`(N,C,H,W)`|이미지 배치|
|**5차원**|5D 텐서|`(N,T,C,H,W)`|동영상 배치|

### 딥러닝에서의 핵심 활용

#### 1) **컴퓨터 비전**

```python
# 이미지 분류
input_batch = torch.randn(32, 3, 224, 224)   # [배치, RGB, 높이, 폭]
conv_output = torch.randn(32, 64, 112, 112)  # [배치, 특성맵, 높이, 폭]
```

#### 2) **자연어 처리**

```python
# 문장 처리
sentences = torch.randn(16, 50, 512)  # [배치, 문장길이, 임베딩차원]
attention = torch.randn(16, 8, 50, 50) # [배치, 헤드, 시퀀스, 시퀀스]
```

#### 3) **시계열 분석**

```python
# 주가 예측
stock_data = torch.randn(100, 30, 5)  # [샘플, 시간윈도우, 특성]
```

### 텐서 연산의 핵심

- **브로드캐스팅**: 다른 크기 텐서 간 연산
- **차원 변환**: reshape, transpose, squeeze, unsqueeze
- **축 따라 연산**: sum, mean, max (특정 차원으로)
- **인덱싱**: 특정 부분 선택 및 수정

### 프레임워크별 구현

```python
# PyTorch
import torch
tensor = torch.randn(2, 3, 4)      # 3차원 텐서
tensor.shape                       # torch.Size([2, 3, 4])
tensor.ndim                        # 3

# TensorFlow
import tensorflow as tf
tensor = tf.random.normal([2, 3, 4])  # 3차원 텐서
tensor.shape                           # TensorShape([2, 3, 4])
tf.rank(tensor)                        # 3

# NumPy
import numpy as np
tensor = np.random.randn(2, 3, 4)  # 3차원 배열
tensor.shape                       # (2, 3, 4)
tensor.ndim                        # 3
```

### 메모리와 성능 고려사항

- **메모리 레이아웃**: 연속적 배치로 캐시 효율 최적화
- **GPU 병렬처리**: 큰 텐서를 여러 코어에서 동시 계산
- **배치 처리**: 여러 샘플을 한 번에 처리해 효율성 향상
- **희소 텐서**: 대부분이 0인 텐서의 효율적 저장

---

## 정리: 차원의 발전과 AI에서의 의미

```
스칼라 → 벡터 → 행렬 → 텐서
  ↓        ↓       ↓       ↓
 점     →  선   →  면   →  공간
(0D)     (1D)    (2D)    (3D+)
```

### 각 단계가 필요한 이유

1. **스칼라 → 벡터**: 단일 값으로는 복잡한 정보(위치, 특성 등) 표현 불가
2. **벡터 → 행렬**: 여러 벡터 간의 관계나 변환 표현 필요
3. **행렬 → 텐서**: 현실의 복잡한 다차원 데이터(이미지, 동영상, 배치) 처리 필요

AI의 발전은 결국 **더 복잡하고 고차원적인 데이터를 효율적으로 처리**하는 방향으로 진화해왔으며, 텐서는 이 모든 것을 통합하는 수학적 프레임워크를 제공한다.